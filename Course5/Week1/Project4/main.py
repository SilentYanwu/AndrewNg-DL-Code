# main.py
'''
çˆµå£«ä¹ç”Ÿæˆå™¨ (TF 2.x å‡çº§ç‰ˆ)
ä»£ç å‚è€ƒï¼šhttps://blog.csdn.net/u013733326/article/details/80890454#t3
'''
import numpy as np
import time
import sys
import IPython.display
import tensorflow as tf
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector
from tensorflow.keras.initializers import glorot_uniform
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K # ä¿ç•™ K ä½œä¸º Keras Backend çš„ç®€å†™

# --- å‡å®šçš„è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥ ---
from music21 import * 
from grammar import *
from qa import *
from preprocess import * 
from music_utils import *
from data_utils import *
# -----------------------------

# --- å…¨å±€å‚æ•°å’Œåˆå§‹åŒ– ---
n_a = 64 # LSTM æ¿€æ´»å•å…ƒçš„æ•°é‡
Tx = 30 # è®­ç»ƒåºåˆ—é•¿åº¦
Ty = 50 # æ¨ç†åºåˆ—é•¿åº¦
n_values = 78 # éŸ³ä¹æ•°æ®ä¸­å”¯ä¸€å€¼çš„æ•°é‡ (éŸ³ç¬¦/ä¼‘æ­¢ç¬¦/å˜åŒ–çš„æ€»æ•°)
m = 60 # è®­ç»ƒæ ·æœ¬æ•°é‡

# åŠ è½½æ•°æ® (å‡è®¾ load_music_utils å·²ç»å‡çº§åˆ° TF2.x å…¼å®¹ç‰ˆæœ¬)
try:
    X, Y, n_values, indices_values = load_music_utils()
    # æ‰“å°æ•°æ®ä¿¡æ¯
    print('âœ… æ•°æ®åŠ è½½æˆåŠŸã€‚')
    print('è¾“å…¥ X çš„å½¢çŠ¶:', X.shape)
    print('è®­ç»ƒæ ·æœ¬æ€»æ•°:', X.shape[0])
    print('Tx (åºåˆ—é•¿åº¦):', X.shape[1])
    print('å”¯ä¸€å€¼æ€»æ•° (n_values):', n_values)
    print('è¾“å‡º Y çš„å½¢çŠ¶:', Y.shape)
except Exception as e:
    print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ music_utils å’Œ data_utils: {e}")
    # è®¾ç½®é»˜è®¤å€¼ä»¥ä½¿æ¨¡å‹å®šä¹‰éƒ¨åˆ†èƒ½å¤Ÿè¿è¡Œ
    n_values = 78 


# åˆå§‹åŒ–å™¨ (ç”¨äºæ¨¡å‹æ¨ç†å’Œè®­ç»ƒ)
x_initializer = np.zeros((1, 1, n_values))
a_initializer = np.zeros((1, n_a))
c_initializer = np.zeros((1, n_a))

# --- æ¨¡å‹ç»„ä»¶å®šä¹‰ (ä½œä¸ºå…¨å±€å˜é‡ï¼Œä¾¿äºåœ¨ djmodel å’Œ music_inference_model ä¸­å…±äº«) ---
# 2.B: Reshape å±‚ï¼Œå°†è¾“å…¥ (Batch, 78) å˜ä¸º (Batch, 1, 78)
reshapor = Reshape((1, n_values)) 
# 2.C: LSTM å•å…ƒï¼Œè¿”å›çŠ¶æ€ï¼Œä¾¿äºåœ¨å¾ªç¯ä¸­ä¼ é€’ (return_sequences=False æ˜¯é»˜è®¤å€¼)
LSTM_cell = LSTM(n_a, return_state = True, name='lstm_cell_shared')
# 2.D: Dense å±‚ï¼Œè¾“å‡º n_values ç»´åº¦çš„æ¦‚ç‡åˆ†å¸ƒ (ä½¿ç”¨ softmax)
densor = Dense(n_values, activation='softmax', name='densor_shared')


def djmodel(Tx, n_a, n_values, reshapor, LSTM_cell, densor):
    """
    å®ç°è®­ç»ƒæ¨¡å‹ (Sequence-to-Sequence with Time-distributed Logic)
    
    å‚æ•°ï¼š
        Tx -- è¯­æ–™åº“çš„é•¿åº¦
        n_a -- æ¿€æ´»å€¼çš„æ•°é‡
        n_values -- éŸ³ä¹æ•°æ®ä¸­å”¯ä¸€å€¼çš„æ•°é‡
        reshapor, LSTM_cell, densor -- å…±äº« Keras å±‚å¯¹è±¡
        
    è¿”å›ï¼š
        model -- Keras æ¨¡å‹å®ä½“
    """
    # å®šä¹‰è¾“å…¥æ•°æ®çš„ç»´åº¦
    X = Input((Tx, n_values), name='X_input')
    
    # å®šä¹‰ a0, c0, åˆå§‹åŒ–éšè—çŠ¶æ€
    a0 = Input(shape=(n_a,), name="a0")
    c0 = Input(shape=(n_a,), name="c0")
    a = a0
    c = c0
    
    # ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºä¸€ä¸ªç©ºçš„outputsåˆ—è¡¨æ¥ä¿å­˜ LSTM çš„æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºã€‚
    outputs = []
    
    # ç¬¬äºŒæ­¥ï¼šå¾ªç¯ Tx æ¬¡ï¼Œå¤„ç†æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥
    for t in range(Tx):
        ## 2.Aï¼šä½¿ç”¨ Lambda å±‚ä» X ä¸­é€‰æ‹©ç¬¬ 't' ä¸ªæ—¶é—´æ­¥å‘é‡
        # Lambda å‡½æ•°ç¡®ä¿åœ¨ TensoFlow Graph ä¸­æ­£ç¡®åˆ‡ç‰‡
        x = Lambda(lambda x_full: x_full[:, t, :], output_shape=(n_values,))(X)
        
        ## 2.Bï¼šä½¿ç”¨ reshapor å¯¹ x è¿›è¡Œé‡æ„ä¸º (Batch, 1, n_values)
        x = reshapor(x)
        
        ## 2.Cï¼šå•æ­¥ä¼ æ’­ (initial_state=[a, c] ä¼ å…¥ä¸Šä¸€æ­¥çš„çŠ¶æ€)
        a, _, c = LSTM_cell(x, initial_state=[a, c])
        
        ## 2.Dï¼šä½¿ç”¨ densor() åº”ç”¨äº LSTM_Cell çš„éšè—çŠ¶æ€è¾“å‡º 'a'
        out = densor(a)
        
        ## 2.Eï¼šæŠŠé¢„æµ‹å€¼æ·»åŠ åˆ° "outputs" åˆ—è¡¨ä¸­
        outputs.append(out)
        
    # ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºæ¨¡å‹å®ä½“
    model = Model(inputs=[X, a0, c0], outputs=outputs, name='DJ_Training_Model')
    
    return model

# è®­ç»ƒæ¨¡å‹å®šä¹‰
model = djmodel(Tx=Tx, n_a=n_a, n_values=n_values, 
                reshapor=reshapor, LSTM_cell=LSTM_cell, densor=densor)

# ç¼–è¯‘æ¨¡å‹ï¼šä½¿ç”¨ Adam ä¼˜åŒ–å™¨ä¸åˆ†ç±»äº¤å‰ç†µæŸå¤±ã€‚
# TF2.x å…¼å®¹æ€§ï¼šAdam å’Œå…¶ä»–ä¼˜åŒ–å™¨ä¸éœ€è¦ K.tf.clip_by_value ç­‰æ“ä½œï¼Œä½†å‚æ•°ä¸ Keras 1/2 å…¼å®¹ã€‚
opt = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

# åˆå§‹åŒ– a0 å’Œ c0ï¼Œç”¨äºè®­ç»ƒæ—¶çš„åˆå§‹çŠ¶æ€ (Batch size = m)
if 'X' in locals():
    m = X.shape[0] # ä½¿ç”¨å®é™…æ ·æœ¬æ•°é‡
a0 = np.zeros((m, n_a))
c0 = np.zeros((m, n_a))

# --- æ¨¡å‹è®­ç»ƒ ---
print("--- å¼€å§‹è®­ç»ƒæ¨¡å‹ ---")
start_time = time.time() # ä½¿ç”¨ time.time() ä»£æ›¿ time.clock() (TF2.x/Python 3 æ¨è)

# å¼€å§‹æ‹Ÿåˆ
# Y å¿…é¡»æ˜¯åˆ—è¡¨å½¢å¼ï¼Œå› ä¸ºæ¨¡å‹æœ‰ Tx ä¸ªè¾“å‡º
if 'X' in locals():
    # ç¡®ä¿ Y æ˜¯æ­£ç¡®çš„åˆ—è¡¨æ ¼å¼ for Keras multi-output
    Y_list = list(Y) 
    
    model.fit([X, a0, c0], Y_list, epochs=100, batch_size=32)
    
    end_time = time.time()
    minium = end_time - start_time
    
    print("\n--- è®­ç»ƒç»“æŸ ---")
    print(f"æ‰§è¡Œäº†: {int(minium / 60)} åˆ† {int(minium % 60)} ç§’")
# --------------------


def music_inference_model(LSTM_cell, densor, n_values=78, n_a=64, Ty=50):
    """
    å®ç°æ¨ç†æ¨¡å‹ (Generating Model)
    åœ¨æ¨ç†æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹ä½¿ç”¨ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ã€‚
    
    å‚æ•°ï¼š
        LSTM_cell -- è®­ç»ƒè¿‡çš„ LSTM å•å…ƒï¼Œæ˜¯ Keras å±‚å¯¹è±¡ã€‚
        densor -- è®­ç»ƒè¿‡çš„ "densor"ï¼Œæ˜¯ Keras å±‚å¯¹è±¡
        Ty -- æ•´æ•°ï¼Œç”Ÿæˆçš„åºåˆ—é•¿åº¦
        
    è¿”å›ï¼š
        inference_model -- Keras æ¨¡å‹å®ä½“
    """
    
    # å®šä¹‰æ¨¡å‹è¾“å…¥çš„ç»´åº¦
    x0 = Input(shape=(1, n_values), name='x0_input')
    
    # å®šä¹‰ a0, c0ï¼Œåˆå§‹åŒ–éšè—çŠ¶æ€
    a0 = Input(shape=(n_a,), name="a0_inf")
    c0 = Input(shape=(n_a,), name="c0_inf")
    a = a0
    c = c0
    x = x0
    
    # æ­¥éª¤1ï¼šåˆ›å»ºä¸€ä¸ªç©ºçš„outputsåˆ—è¡¨æ¥ä¿å­˜é¢„æµ‹å€¼ã€‚
    outputs = []
    
    # æ­¥éª¤2ï¼šéå† Tyï¼Œç”Ÿæˆæ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡º
    for t in range(Ty):
        
        # æ­¥éª¤2.Aï¼šåœ¨ LSTM ä¸­å•æ­¥ä¼ æ’­ (x æ˜¯ä¸Šä¸€æ­¥ç”Ÿæˆçš„ one-hot å‘é‡)
        a, _, c = LSTM_cell(x, initial_state=[a, c])
        
        # æ­¥éª¤2.Bï¼šä½¿ç”¨ densor() åº”ç”¨äº LSTM_Cell çš„éšè—çŠ¶æ€è¾“å‡º 'a'
        out = densor(a)
        
        # æ­¥éª¤2.Cï¼šé¢„æµ‹å€¼æ·»åŠ åˆ° "outputs" åˆ—è¡¨ä¸­
        outputs.append(out)
        
        # æ­¥éª¤2.Dï¼šæ ¹æ® 'out' é€‰æ‹©ä¸‹ä¸€ä¸ªå€¼ï¼Œå¹¶å°†å…¶ one-hot ç¼–ç è®¾ç½®ä¸º 'x'
        # one_hot åº”è¯¥æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰çš„ Lambda å‡½æ•°ï¼Œç”¨äºä»æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·æˆ–é€‰æ‹© max
        # è¿™é‡Œä½¿ç”¨ Lambda(one_hot) ç¡®ä¿å®ƒåœ¨ Keras å›¾ä¸­æ‰§è¡Œ
        # one_hot å‡½æ•°å·²åœ¨ data_utils æˆ– music_utils ä¸­å®šä¹‰ (è§å‰ä¸€ä¸ªè¯·æ±‚çš„å®ç°)
        x = Lambda(one_hot)(out)
        
    # åˆ›å»ºæ¨¡å‹å®ä½“
    inference_model = Model(inputs=[x0, a0, c0], outputs=outputs, name='Music_Inference_Model')
    
    return inference_model

# è·å–æ¨ç†æ¨¡å‹å®ä½“ (ç¡¬ç¼–ç  Ty = 50)
inference_model = music_inference_model(LSTM_cell, densor, n_values=n_values, n_a=n_a, Ty=Ty)

# åˆ›å»ºç”¨äºåˆå§‹åŒ– x å’Œ LSTM çŠ¶æ€å˜é‡ a å’Œ c çš„é›¶å‘é‡ã€‚
x_initializer = np.zeros((1, 1, n_values))
a_initializer = np.zeros((1, n_a))
c_initializer = np.zeros((1, n_a))


def predict_and_sample(inference_model, x_initializer=x_initializer, a_initializer=a_initializer, 
                       c_initializer=c_initializer):
    """
    ä½¿ç”¨æ¨ç†æ¨¡å‹è¿›è¡Œé¢„æµ‹å’Œé‡‡æ ·ã€‚
    
    å‚æ•°ï¼š
        inference_model -- Keras çš„å®ä½“æ¨¡å‹
        ... åˆå§‹çŠ¶æ€
    
    è¿”å›ï¼š
        results -- ç”Ÿæˆå€¼çš„ç‹¬çƒ­ç¼–ç å‘é‡ï¼Œç»´åº¦ä¸º(Ty, 78)
        indices -- æ‰€ç”Ÿæˆå€¼çš„ç´¢å¼•çŸ©é˜µï¼Œç»´åº¦ä¸º(Ty, 1)
    """
    # æ­¥éª¤1ï¼šæ¨¡å‹æ¥é¢„æµ‹ç»™å®šåˆå§‹çŠ¶æ€çš„è¾“å‡ºåºåˆ— (è¿”å› Ty ä¸ªæ¦‚ç‡åˆ†å¸ƒçŸ©é˜µ)
    pred = inference_model.predict([x_initializer, a_initializer, c_initializer])
    
    # æ­¥éª¤2ï¼šå°†â€œpredâ€è½¬æ¢ä¸ºå…·æœ‰æœ€å¤§æ¦‚ç‡çš„ç´¢å¼•æ•°ç»„ np.array()ã€‚
    # pred æ˜¯ä¸€ä¸ªåŒ…å« Ty ä¸ªå…ƒç´ çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ å½¢çŠ¶æ˜¯ (1, 78)ã€‚
    # æˆ‘ä»¬å°†å®ƒä»¬å †å èµ·æ¥ï¼Œå¹¶æ²¿ç€æœ€åä¸€ä¸ªè½´ (axis=-1) å–æœ€å¤§å€¼ç´¢å¼•ã€‚
    pred_array = np.array(pred) # å½¢çŠ¶: (Ty, 1, 78)
    indices = np.argmax(pred_array, axis=-1) # å½¢çŠ¶: (Ty, 1)
    
    # æ­¥éª¤3ï¼šå°†ç´¢å¼•è½¬æ¢ä¸ºå®ƒä»¬çš„ä¸€ä¸ªç‹¬çƒ­ç¼–ç ã€‚
    results = to_categorical(indices.squeeze(), num_classes=n_values) # å½¢çŠ¶: (Ty, 78)
    
    return results, indices

# --- éŸ³ä¹ç”Ÿæˆå’Œæµ‹è¯• ---
print("\n--- å¼€å§‹éŸ³ä¹ç”Ÿæˆæµ‹è¯• ---")
results, indices = predict_and_sample(inference_model, x_initializer, a_initializer, c_initializer)
print(f"ç”Ÿæˆçš„åºåˆ—é•¿åº¦ (Ty): {Ty}")
print(f"ç¬¬ 13 ä¸ªå€¼çš„ç´¢å¼• (np.argmax(results[12])): {np.argmax(results[12])}")
print(f"ç¬¬ 18 ä¸ªå€¼çš„ç´¢å¼• (np.argmax(results[17])): {np.argmax(results[17])}")
print(f"ç´¢å¼• 12 åˆ° 17: {list(indices[12:18].flatten())}")

# ç”Ÿæˆæœ€ç»ˆçš„ MIDI æ–‡ä»¶ (å‡è®¾ generate_music å·²ç»å‡çº§åˆ° TF2.x å…¼å®¹ç‰ˆæœ¬)
if 'inference_model' in locals():
    print("\n--- å¼€å§‹ç”Ÿæˆ MIDI æ–‡ä»¶ ---")
    out_stream = generate_music(inference_model, Ty=Ty)
    print("âœ… MIDI æ–‡ä»¶ç”Ÿæˆå®Œæ¯•: output/my_music.midi")


# --- ä»»åŠ¡ 3: å°†ç”Ÿæˆçš„ MIDI è½¬åŒ–ä¸º MP3 å¹¶æ’­æ”¾ ---

# âš  æ³¨æ„ï¼šMIDI è½¬ MP3 éœ€è¦å¤–éƒ¨åº“å’Œç³»ç»Ÿç¯å¢ƒæ”¯æŒï¼Œä¾‹å¦‚ MuseScore æˆ– TiMidity++ã€‚
# åœ¨æ ‡å‡†çš„ Python/Colab/Jupyter ç¯å¢ƒä¸­ï¼Œæœ€ç®€å•çš„æ–¹æ³•æ˜¯ä½¿ç”¨ music21 åº“çš„ converter/midi.realtime æ¨¡å—ï¼Œ
# é…åˆå®‰è£…å¥½çš„ MIDI æ’­æ”¾å™¨/åˆæˆå™¨ã€‚

def convert_midi_to_mp3_and_play(stream_obj):
    """
    å°† music21 stream å¯¹è±¡è½¬åŒ–ä¸º MIDI æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„å·¥å…·å°†å…¶æ¸²æŸ“ä¸º MP3 (æˆ– wav) å¹¶æ’­æ”¾ã€‚
    
    å‚æ•°:
        stream_obj -- music21.stream.Stream å¯¹è±¡
    """
    # 1. ä¿å­˜ MIDI æ–‡ä»¶ (å·²åœ¨ generate_music ä¸­å®Œæˆï¼Œä½†æ­¤å¤„å†æ¬¡ç¡®è®¤è·¯å¾„)
    midi_path = "output/my_music.midi"
    
    # 2. å°è¯• MIDI å®æ—¶æ’­æ”¾ (é€šå¸¸åœ¨æœ¬åœ°å®‰è£…äº† music21 æ‰€ä¾èµ–çš„æ’­æ”¾å™¨æ—¶æœ‰æ•ˆ)
    print("\n--- å°è¯•å®æ—¶æ’­æ”¾ MIDI ---")
    try:
        # music21.midi.realtime.StreamPlayer ä¾èµ–äºåº•å±‚ MIDI åˆæˆå™¨ï¼Œå¦‚ fluidsynth æˆ– timidity
        sp = midi.realtime.StreamPlayer(stream_obj)
        sp.play()
        print("âœ… MIDI å®æ—¶æ’­æ”¾æˆåŠŸ (å¦‚æœé…ç½®äº† MIDI åˆæˆå™¨)ã€‚")
    except Exception as e:
        print(f"âŒ MIDI å®æ—¶æ’­æ”¾å¤±è´¥: {e}")
        
    # 3. å°è¯•æ¸²æŸ“ä¸º MP3/WAV (éœ€è¦å¤–éƒ¨å·¥å…·ï¼Œå¦‚ MuseScore)
    # è¿™ä¸€æ­¥åœ¨çº¯ Python/TF ç¯å¢ƒä¸­éå¸¸å¤æ‚ï¼Œé€šå¸¸éœ€è¦å®‰è£…å’Œé…ç½® MuseScoreã€‚
    # ä»¥ä¸‹ä»£ç ä»…ä¸ºç¤ºæ„ï¼Œå®é™…è¿è¡Œéœ€è¦æ­£ç¡®çš„ç¯å¢ƒé…ç½®ã€‚
    print("\n--- å°è¯•å°† MIDI æ¸²æŸ“ä¸º MP3 ---")
    try:
        # ä½¿ç”¨ music21 çš„ show() æ–¹æ³•å°è¯•æ¸²æŸ“ï¼Œä¾èµ–äº MuseScore æˆ–å…¶ä»– MusicXML æ¸²æŸ“å™¨
        # stream_obj.show('midi') # å°è¯•ç”¨é»˜è®¤ MIDI æ’­æ”¾å™¨æ‰“å¼€
        
        # å‡è®¾æˆ‘ä»¬æˆåŠŸä½¿ç”¨å¤–éƒ¨å·¥å…· (å¦‚ os.system("musescore /path/to/midi -o /path/to/mp3")) 
        # è½¬æ¢ä¸º output/my_music.mp3
        mp3_path = "output/my_music.mp3"
        print(f"ğŸ’¡ MIDI è½¬ MP3/WAV æ¸²æŸ“éœ€è¦å¤–éƒ¨å·¥å…· (å¦‚ MuseScore æˆ– TiMidity++)ã€‚è¯·æ‰‹åŠ¨è¿è¡Œæˆ–é…ç½®ã€‚")

        # æ¨¡æ‹Ÿæ’­æ”¾ MP3 (å¦‚æœæ–‡ä»¶å­˜åœ¨)
        if os.path.exists(mp3_path):
             IPython.display.display(IPython.display.Audio(mp3_path))
             print("âœ… MP3 æ–‡ä»¶æ’­æ”¾æˆåŠŸã€‚")
        else:
            # ä»…æ’­æ”¾ MIDI æ–‡ä»¶ä½œä¸ºæ›¿ä»£
            IPython.display.display(IPython.display.Audio(midi_path))
            print("ğŸ’¡ æ— æ³•æ‰¾åˆ° MP3 æ–‡ä»¶ï¼Œå°è¯•æ’­æ”¾åŸå§‹ MIDI æ–‡ä»¶ (æµè§ˆå™¨æ”¯æŒ)ã€‚")
            
    except Exception as e:
        print(f"âŒ MIDI æ¸²æŸ“æˆ– MP3 æ’­æ”¾å¤±è´¥: {e}")

# æ’­æ”¾ç”Ÿæˆçš„éŸ³ä¹
if 'out_stream' in locals():
    convert_midi_to_mp3_and_play(out_stream)