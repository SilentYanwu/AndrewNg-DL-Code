# infer.py
import torch
import cv2
import numpy as np
import os, sys
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms
import argparse

# æ·»åŠ è·¯å¾„ä¿®å¤ä»£ç 
def fix_paths():
    """ä¿®å¤å¯¼å…¥è·¯å¾„å’Œæ–‡ä»¶è·¯å¾„"""
    # å°†å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # åˆ‡æ¢åˆ°å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
    os.chdir(current_dir)

# åœ¨å¯¼å…¥æœ¬åœ°æ–‡ä»¶/æ¨¡å‹ä¹‹å‰è°ƒç”¨
fix_paths()

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from resnet_model import create_resnet50 # å¯¼å…¥æ–°çš„ ResNet æ¨¡å‹

# è®¾ç½® Matplotlib ä¸­æ–‡æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# å…³é”®ï¼šå¿…é¡»ä½¿ç”¨ä¸è®­ç»ƒæ—¶ *å®Œå…¨ç›¸åŒ* çš„å°ºå¯¸å’Œå½’ä¸€åŒ–å‚æ•°
INFER_SIZE = 64
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

def load_model(model_path, device):
    """
    åŠ è½½è®­ç»ƒå¥½çš„ ResNet-50 æ¨¡å‹
    """
    # 1. åˆå§‹åŒ–æ¨¡å‹ç»“æ„
    #    é‡è¦ï¼šuse_pretrained=Falseï¼Œå› ä¸ºæˆ‘ä»¬ä¸æ˜¯åŠ è½½ ImageNet æƒé‡ï¼Œ
    #    è€Œæ˜¯åŠ è½½æˆ‘ä»¬è‡ªå·±è®­ç»ƒå¥½çš„ .pt æ–‡ä»¶ã€‚
    model = create_resnet50(num_classes=6, use_pretrained=False).to(device)
    
    # 2. åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    #    map_location ç¡®ä¿åœ¨æ²¡æœ‰ GPU çš„æœºå™¨ä¸Šä¹Ÿèƒ½åŠ è½½
    model.load_state_dict(torch.load(model_path, map_location=device))
    
    # 3. è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    return model

def preprocess_image(image_path_or_array):
    """
    å›¾åƒé¢„å¤„ç†å‡½æ•°ï¼šå¤„ç†æ–‡ä»¶è·¯å¾„æˆ–numpyæ•°ç»„
    """
    if isinstance(image_path_or_array, str):
        image = cv2.imread(image_path_or_array)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path_or_array}")
    else:
        image = image_path_or_array

    # 1. é¢œè‰²ç©ºé—´è½¬æ¢ï¼šBGR -> RGB
    if len(image.shape) == 2:
        image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    else:
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
    # 2. è½¬æ¢ä¸ºPIL Imageæ ¼å¼
    image_pil = Image.fromarray(image_rgb)
    
    # 3. åº”ç”¨ä¸ *éªŒè¯é›†/æµ‹è¯•é›†* å®Œå…¨ç›¸åŒçš„é¢„å¤„ç†å˜æ¢
    preprocess_transform = transforms.Compose([
        transforms.Resize((INFER_SIZE, INFER_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
    ])
    
    # 4. åº”ç”¨å˜æ¢å¹¶å¢åŠ batchç»´åº¦ [C, H, W] -> [1, C, H, W]
    image_tensor = preprocess_transform(image_pil).unsqueeze(0)
    
    return image_tensor, image_rgb

def predict_and_show(model, image_path, device, classes):
    """
    æ‰§è¡Œå•å¼ å›¾ç‰‡é¢„æµ‹å¹¶å¯è§†åŒ–ç»“æœ (æ»¡è¶³æ‚¨çš„ 'show' è¦æ±‚)
    """
    try:
        tensor, original_rgb = preprocess_image(image_path)
        tensor = tensor.to(device)
    except ValueError as e:
        print(f"âŒ å›¾åƒå¤„ç†é”™è¯¯: {e}")
        return

    # æ¨¡å‹æ¨ç†
    with torch.no_grad():
        outputs = model(tensor)
        probs = torch.softmax(outputs, dim=1)
        conf, pred = torch.max(probs, 1)
        
        label = str(classes[pred.item()]) # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿æ˜¾ç¤º
        conf_value = conf.item() * 100

    print(f"ğŸ“ æ–‡ä»¶: {os.path.basename(image_path)}")
    print(f"   ğŸ¯ é¢„æµ‹ç±»åˆ«: {label}")
    print(f"   ğŸ“Š ç½®ä¿¡åº¦: {conf_value:.2f}%")

    # ä½¿ç”¨ Matplotlib æ˜¾ç¤ºç»“æœ (æ»¡è¶³ 'show' è¦æ±‚)
    plt.figure(figsize=(8, 6))
    plt.imshow(original_rgb)
    title_text = f"é¢„æµ‹ç»“æœ: {label} (ç½®ä¿¡åº¦: {conf_value:.2f}%)"
    plt.title(title_text, fontsize=14, fontweight='bold')
    plt.axis("off")
    plt.tight_layout()
    plt.show()

def batch_predict(model, input_dir, device, classes):
    """
    æ‰¹é‡é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡ (æ»¡è¶³æ‚¨çš„ 'æ‰¹é‡è¯†åˆ«' è¦æ±‚)
    """
    print(f"ğŸ” æ‰«ææ–‡ä»¶å¤¹: {input_dir}")
    valid_extensions = ('.jpg', '.png', '.jpeg', '.bmp', '.tiff')
    
    for filename in os.listdir(input_dir):
        if filename.lower().endswith(valid_extensions):
            img_path = os.path.join(input_dir, filename)
            
            try:
                tensor, _ = preprocess_image(img_path)
                tensor = tensor.to(device)
                
                with torch.no_grad():
                    outputs = model(tensor)
                    probs = torch.softmax(outputs, dim=1)
                    conf, pred = torch.max(probs, 1)
                    
                    label = str(classes[pred.item()])
                    conf_value = conf.item() * 100
                    print(f"  ğŸ“„ {filename:<20} -> ğŸ¯ {label} ({conf_value:.2f}%)")
                    
            except Exception as e:
                print(f"  âŒ è·³è¿‡ {filename}: {e}")

def main():
    while True:
    # äº¤äº’å¼è¾“å…¥å›¾ç‰‡è·¯å¾„
        parser = argparse.ArgumentParser(description="æ‰‹è¯­ ResNet-50 æ¨¡å‹æ¨ç†å·¥å…·")
        parser.add_argument('-m', '--model', type=str, default='runs/best_model.pt',
                        help='è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„ (.pt æ–‡ä»¶)')
        test_image = input("ğŸ“ è¯·è¾“å…¥è¦é¢„æµ‹çš„å›¾ç‰‡è·¯å¾„ï¼š")
        parser.add_argument('-i', '--input', type=str, default=test_image,
                            help='è¦é¢„æµ‹çš„å›¾ç‰‡è·¯å¾„æˆ–å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„')
        args = parser.parse_args()
        
        # 1. è®¾ç½®è®¾å¤‡
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ–¥ï¸ æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device}")
        
        # 2. å®šä¹‰ç±»åˆ«æ ‡ç­¾ (0-5)
        classes = [0, 1, 2, 3, 4, 5]
        
        # 3. åŠ è½½æ¨¡å‹
        if not os.path.exists(args.model):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {args.model}")
            print("è¯·å…ˆè¿è¡Œ train_resnet.py è®­ç»ƒæ¨¡å‹ã€‚")
            return
            
        print(f"ğŸ“¦ æ­£åœ¨ä» {args.model} åŠ è½½æ¨¡å‹...")
        try:
            model = load_model(args.model, device)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return
        
        # 4. æ ¹æ®è¾“å…¥ç±»å‹æ‰§è¡Œä¸åŒæ¨¡å¼
        if not os.path.exists(args.input):
            print(f"âŒ é”™è¯¯: è¾“å…¥è·¯å¾„æ— æ•ˆ: {args.input}")
            return

        if os.path.isfile(args.input):
            print("\n--- æ¨¡å¼: å•å¼ å›¾ç‰‡é¢„æµ‹ ---")
            predict_and_show(model, args.input, device, classes)
            
        elif os.path.isdir(args.input):
            print("\n--- æ¨¡å¼: æ‰¹é‡æ–‡ä»¶å¤¹é¢„æµ‹ ---")
            batch_predict(model, args.input, device, classes)

        # 5. è¯¢é—®æ˜¯å¦ç»§ç»­é¢„æµ‹
            cont = input("\nğŸ”„ æ˜¯å¦ç»§ç»­é¢„æµ‹å…¶ä»–å›¾ç‰‡ï¼Ÿ(y/n): ")
            if cont.lower() != 'y':
                print("ğŸ‘‹ é€€å‡ºé¢„æµ‹ç¨‹åºã€‚")
                break
if __name__ == "__main__":
    main()
    print("ğŸ‘‹ è°¢è°¢ä½¿ç”¨")