# train_resnet.py
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
import matplotlib.pyplot as plt
import argparse
from torch.optim.lr_scheduler import ReduceLROnPlateau
import os,sys
# æ·»åŠ è·¯å¾„ä¿®å¤ä»£ç 
def fix_paths():
    """ä¿®å¤å¯¼å…¥è·¯å¾„å’Œæ–‡ä»¶è·¯å¾„"""
    # å°†å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # åˆ‡æ¢åˆ°å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
    os.chdir(current_dir)

# åœ¨å¯¼å…¥æœ¬åœ°æ–‡ä»¶/æ¨¡å‹ä¹‹å‰è°ƒç”¨
fix_paths()

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from dataset import SignLanguageDataset
from resnet_model import create_resnet50

# è®¾ç½® Matplotlib ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# å›¾åƒå°ºå¯¸å’Œæ ‡å‡†åŒ–ï¼ˆä½¿ç”¨ ImageNet å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå› ä¸ºæˆ‘ä»¬ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰
IMG_SIZE = 64
IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

def get_data_loaders(data_dir, batch_size):
    """
    å‡†å¤‡æ•°æ®åŠ è½½å™¨ï¼ŒåŒ…å«æ•°æ®å¢å¼ºå’Œè®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†
    """
    
    # è®­ç»ƒé›†çš„æ•°æ®å¢å¼º
    train_transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        # æ·»åŠ æ›´å¼ºçš„å¢å¼º
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(30),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),
        transforms.ToTensor(),
        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD) # å…³é”®ï¼šä½¿ç”¨ ImageNet å½’ä¸€åŒ–
    ])

    # éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸éœ€è¦å¢å¼º
    val_test_transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD) # å…³é”®ï¼šä½¿ç”¨ ImageNet å½’ä¸€åŒ–
    ])
    
    # åŠ è½½å®Œæ•´è®­ç»ƒé›† (ä½¿ç”¨å¢å¼º)
    full_train_dataset = SignLanguageDataset(
        os.path.join(data_dir, 'train_signs.h5'), 
        set_name='train_set', 
        transform=train_transform
    )
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›† (90% è®­ç»ƒ, 10% éªŒè¯)
    train_size = int(0.9 * len(full_train_dataset))
    val_size = len(full_train_dataset) - train_size
    
    # ä½¿ç”¨å›ºå®šçš„éšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡åˆ’åˆ†ä¸€è‡´
    train_dataset, val_dataset = random_split(
        full_train_dataset, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    # ï¼ï¼é‡è¦ï¼ï¼ å°†éªŒè¯é›†çš„æ•°æ®å˜æ¢æ›¿æ¢ä¸º *ä¸å¢å¼º* çš„ç‰ˆæœ¬
    # random_split åçš„ val_dataset ä»ç„¶æŒ‡å‘ full_train_dataset
    # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæŠ€å·§æ¥ä¿®æ”¹å®ƒçš„ transform
    # æœ€ç®€å•çš„æ–¹æ³•æ˜¯é‡æ–°åˆ›å»ºä¸€æ¬¡ val_datasetï¼Œä½†è¿™ä¼šé‡å¤åŠ è½½æ•°æ®
    # æ›´é«˜æ•ˆçš„æ–¹å¼æ˜¯åˆ›å»ºä¸€ä¸ªåŒ…è£…å™¨æˆ–ä¿®æ”¹ val_dataset.dataset
    # ä¸ºäº†ç®€å•å’Œå®‰å…¨ï¼Œæˆ‘ä»¬è¿™é‡Œé‡æ–°åŠ è½½ä¸€æ¬¡ï¼ˆè™½ç„¶æ•ˆç‡ç¨ä½ï¼‰
    
    # æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ–°çš„å®ä¾‹ç”¨äºéªŒè¯ï¼Œä»…ä¸ºäº†åº”ç”¨æ­£ç¡®çš„ transform
    # æ³¨æ„ï¼šè¿™å‡è®¾ val_dataset.indices å­˜å‚¨äº†æ­£ç¡®çš„ç´¢å¼•
    # ä¸€ä¸ªæ›´å¹²å‡€çš„æ–¹æ³•æ˜¯è®© SignLanguageDataset æ¥å—ä¸€ä¸ªç´¢å¼•åˆ—è¡¨
    # ä½†æˆ‘ä»¬ä¿æŒæ‚¨åŸæœ‰çš„ dataset.py ä¸å˜ï¼Œé‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼š
    
    # ç­–ç•¥è°ƒæ•´ï¼šåœ¨ random_split ä¹‹åï¼Œæˆ‘ä»¬ä¿®æ”¹ val_dataset çš„ transform
    # å¹¸è¿çš„æ˜¯ï¼ŒPyTorch çš„ Subset å¯¹è±¡å…è®¸æˆ‘ä»¬è®¿é—®å…¶åº•å±‚çš„ dataset
    # æˆ‘ä»¬å¯ä»¥ *ä¸´æ—¶* ä¿®æ”¹åº•å±‚ dataset çš„ transform
    # ä½†è¿™ä¼šå¸¦æ¥é£é™©ï¼Œå› ä¸º train_dataset ä¹Ÿå…±äº«å®ƒ
    
    # æœ€å®‰å…¨ã€æœ€æ¸…æ™°çš„ç­–ç•¥ï¼š
    # 1. åŠ è½½ä¸¤æ¬¡ train_signs.h5
    dataset_for_train = SignLanguageDataset(
        os.path.join(data_dir, 'train_signs.h5'), 
        set_name='train_set', 
        transform=train_transform
    )
    dataset_for_val = SignLanguageDataset(
        os.path.join(data_dir, 'train_signs.h5'), 
        set_name='train_set', 
        transform=val_test_transform # éªŒè¯é›†ä½¿ç”¨ *æ— å¢å¼º* å˜æ¢
    )
    
    # 2. ä½¿ç”¨ç›¸åŒçš„ç§å­å’Œç´¢å¼•è¿›è¡Œåˆ’åˆ†
    indices = torch.randperm(len(dataset_for_train), generator=torch.Generator().manual_seed(42)).tolist()
    train_indices = indices[:train_size]
    val_indices = indices[train_size:]
    
    train_dataset = torch.utils.data.Subset(dataset_for_train, train_indices)
    val_dataset = torch.utils.data.Subset(dataset_for_val, val_indices)


    # åŠ è½½æµ‹è¯•é›†
    test_dataset = SignLanguageDataset(
        os.path.join(data_dir, 'test_signs.h5'), 
        set_name='test_set', 
        transform=val_test_transform
    )

    # åˆ›å»º DataLoaders
    # ä½¿ç”¨ num_workers > 0 æ¥åˆ©ç”¨æ‚¨å®‰å…¨çš„ dataset.py
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)
    
    print(f"æ€»è®­ç»ƒæ ·æœ¬: {len(full_train_dataset)} -> æ‹†åˆ†ä¸º:")
    print(f"   - è®­ç»ƒé›†: {len(train_dataset)}")
    print(f"   - éªŒè¯é›†: {len(val_dataset)}")
    print(f"æµ‹è¯•é›†: {len(test_dataset)}")
    
    return train_loader, val_loader, test_loader

def train_one_epoch(model, loader, optimizer, criterion, device, scaler):
    """
    è®­ç»ƒä¸€ä¸ªepoch (æ”¯æŒæ··åˆç²¾åº¦)
    """
    model.train()
    running_loss = 0.0
    
    for inputs, labels in loader:
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        
        # ä½¿ç”¨æ··åˆç²¾åº¦
        with torch.cuda.amp.autocast():
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
        # ç¼©æ”¾æ¢¯åº¦
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        running_loss += loss.item()
        
    return running_loss / len(loader)

def validate(model, loader, criterion, device):
    """
    åœ¨éªŒè¯é›†æˆ–æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
    """
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for inputs, labels in loader:
            inputs, labels = inputs.to(device), labels.to(device)
            
            # è¯„ä¼°æ—¶ä¹Ÿä½¿ç”¨æ··åˆç²¾åº¦
            with torch.cuda.amp.autocast():
                outputs = model(inputs)
                loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
    avg_loss = running_loss / len(loader)
    accuracy = 100 * correct / total
    return avg_loss, accuracy

def main(args):
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # 1. è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 2. åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    
    # 3. è·å–æ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader = get_data_loaders(args.data_dir, args.batch_size)
    
    # 4. åˆå§‹åŒ–æ¨¡å‹
    #    (åˆ›å»ºé¢„è®­ç»ƒã€å†»ç»“å·ç§¯å±‚çš„æ¨¡å‹)
    model = create_resnet50(
        num_classes=6, 
        use_pretrained=True, 
        freeze_layers=True  # å…ˆå†»ç»“è®­ç»ƒ
    ).to(device)
    
    # 5. å®šä¹‰æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦å™¨
    criterion = nn.CrossEntropyLoss()
    
    # ä»…ä¼˜åŒ–è§£å†»çš„å‚æ•° (è¿™é‡Œæ˜¯ model.fc)
    optimizer = optim.Adam(
        filter(lambda p: p.requires_grad, model.parameters()), 
        lr=args.lr
    )
    
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)
    
    # 6. åˆå§‹åŒ–æ··åˆç²¾åº¦ (AMP) ç¼©æ”¾å™¨
    scaler = torch.amp.GradScaler()
    
    # 7. è®­ç»ƒå¾ªç¯
    best_val_acc = 0.0
    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}
    # è¿ç§»å­¦ä¹ é˜¶æ®µçš„ä»£ç 
    print("\n--- é˜¶æ®µ 1: è®­ç»ƒåˆ†ç±»å¤´ (å†»ç»“å·ç§¯å±‚) ---")
    for epoch in range(args.epochs):
        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)
        val_loss, val_acc = validate(model, val_loader, criterion, device)
        
        scheduler.step(val_loss)
        
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        
        print(f"Epoch {epoch+1:02d}/{args.epochs:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
        
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            save_path = os.path.join(args.save_dir, "best_model.pt")
            torch.save(model.state_dict(), save_path)
            print(f"  ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! å‡†ç¡®ç‡: {best_val_acc:.2f}%. å·²ä¿å­˜åˆ° {save_path}")

    # 8. (å¯é€‰ä½†æ¨è) è§£å†»æ¨¡å‹å¹¶è¿›è¡Œç«¯åˆ°ç«¯å¾®è°ƒ
    print("\n--- é˜¶æ®µ 2: è§£å†»å¹¶å¾®è°ƒ (End-to-End Fine-tuning) ---")
    # è§£å†»æ‰€æœ‰å±‚
    for param in model.parameters():
        param.requires_grad = True
        
    # ä¸ºè§£å†»åçš„æ¨¡å‹åˆ›å»ºä¸€ä¸ªæ–°çš„ä¼˜åŒ–å™¨ï¼Œä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
    optimizer = optim.Adam(model.parameters(), lr=args.lr / 10) # ä½¿ç”¨ 1/10 çš„å­¦ä¹ ç‡
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)
    
    # å†è®­ç»ƒå‡ ä¸ª epochs
    fine_tune_epochs = args.epochs // 2 # æ¯”å¦‚å†è®­ç»ƒ 1/2 çš„è½®æ•°
    
    for epoch in range(fine_tune_epochs):
        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)
        val_loss, val_acc = validate(model, val_loader, criterion, device)
        
        scheduler.step(val_loss)
        
        # è®°å½•åˆ° history
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        
        print(f"Fine-tune Epoch {epoch+1:02d}/{fine_tune_epochs:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
        
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            save_path = os.path.join(args.save_dir, "best_model.pt")
            torch.save(model.state_dict(), save_path)
            print(f"  ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹ (Fine-tuned)! å‡†ç¡®ç‡: {best_val_acc:.2f}%. å·²ä¿å­˜åˆ° {save_path}")

    print("âœ… è®­ç»ƒå®Œæˆã€‚")
    
    # 9. ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='è®­ç»ƒæŸå¤±')
    plt.plot(history['val_loss'], label='éªŒè¯æŸå¤±')
    plt.axvline(x=args.epochs-1, color='gray', linestyle='--', label='Fine-tune å¼€å§‹')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title("æŸå¤±æ›²çº¿")
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.plot(history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡', color='orange')
    plt.axvline(x=args.epochs-1, color='gray', linestyle='--', label='Fine-tune å¼€å§‹')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy (%)')
    plt.title("éªŒè¯å‡†ç¡®ç‡æ›²çº¿")
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(os.path.join(args.save_dir, "training_curves.png"))
    print(f"ğŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ° {args.save_dir}/training_curves.png")
    plt.show()
    
    # 10. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ç»ˆçš„æœ€ä½³æ¨¡å‹
    print("ğŸ§ª æ­£åœ¨ç”¨æµ‹è¯•é›†è¯„ä¼°æœ€ä½³æ¨¡å‹...")
    model.load_state_dict(torch.load(os.path.join(args.save_dir, "best_model.pt")))
    test_loss, test_acc = validate(model, test_loader, criterion, device)
    print(f"âœ… æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.2f}%")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è®­ç»ƒæ‰‹è¯­ ResNet-50 æ¨¡å‹")
    parser.add_argument('--data_dir', type=str, default='datasets', help='H5 æ•°æ®é›†æ‰€åœ¨æ–‡ä»¶å¤¹')
    parser.add_argument('--save_dir', type=str, default='runs', help='æ¨¡å‹ä¿å­˜æ–‡ä»¶å¤¹')
    parser.add_argument('--lr', type=float, default=1e-3, help='åˆå§‹å­¦ä¹ ç‡ (ç”¨äºè®­ç»ƒåˆ†ç±»å¤´)')
    parser.add_argument('--epochs', type=int, default=20, help='*åˆå§‹*è®­ç»ƒè½®æ•° (ä»…åˆ†ç±»å¤´)')
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹å¤„ç†å¤§å°')
    
    args = parser.parse_args()
    main(args)