# -*- coding: utf-8 -*-
# =========================================================
# åŠŸèƒ½: åŠ è½½è®­ç»ƒå¥½çš„ cat_model.pth æ¨¡å‹ï¼Œå¯¹å•å¼ å›¾ç‰‡è¿›è¡ŒçŒ«/éçŒ«é¢„æµ‹
# =========================================================

import torch
import torch.nn as nn
import cv2
import numpy as np
import matplotlib.pyplot as plt
from torchvision import transforms
import os,sys

# =========================================================
# é›¶ã€è·¯å¾„å’Œå­—ä½“
# =========================================================
# æ·»åŠ è·¯å¾„ä¿®å¤ä»£ç 
def fix_paths():
    """ä¿®å¤å¯¼å…¥è·¯å¾„å’Œæ–‡ä»¶è·¯å¾„"""
    # å°†å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # åˆ‡æ¢åˆ°å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
    os.chdir(current_dir)

# åœ¨å¯¼å…¥æœ¬åœ°ä¹‹å‰è°ƒç”¨
fix_paths()

# è®¾ç½® Matplotlib ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„å­—ä½“ï¼ˆWindows æ¨è SimHeiï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei']   # æˆ–è€… ['Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False     # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# =========================================================
# ä¸€ã€è®¾å¤‡è®¾ç½®ï¼ˆGPU ä¼˜å…ˆï¼‰
# =========================================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"å½“å‰è®¾å¤‡: {device}")

# =========================================================
# äºŒã€å®šä¹‰æ¨¡å‹ç»“æ„ï¼ˆéœ€ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰
# =========================================================
class LLayerNet(nn.Module):
    def __init__(self, layer_dims, dropout_prob=0.3):
        super(LLayerNet, self).__init__()
        layers = []
        for i in range(1, len(layer_dims)):
            layers.append(nn.Linear(layer_dims[i - 1], layer_dims[i]))  # å…¨è¿æ¥å±‚
            if i < len(layer_dims) - 1:  # æœ€åä¸€å±‚ä¸åŠ æ¿€æ´»
                layers.append(nn.BatchNorm1d(layer_dims[i]))  # åŠ  BatchNorm
                layers.append(nn.ReLU())                     # æ¿€æ´»å‡½æ•°
                layers.append(nn.Dropout(p=dropout_prob))     # åŠ  Dropout
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        x = x.view(x.size(0), -1)  # å±•å¹³å›¾åƒ
        out = self.model(x)
        return torch.sigmoid(out)

# åˆå§‹åŒ–ç½‘ç»œï¼ˆå¿…é¡»ä¸è®­ç»ƒæ–‡ä»¶çš„ç»“æ„ä¸€è‡´ï¼‰
layer_dims = [64*64*3, 64, 32, 8, 1]
model = LLayerNet(layer_dims).to(device)

# =========================================================
# ä¸‰ã€åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å‚æ•°
# =========================================================
model_path = "cat_model.pth"
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()
print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹å‚æ•°ï¼š{model_path}")

# =========================================================
# å››ã€å›¾ç‰‡é¢„å¤„ç†å‡½æ•°ï¼ˆä¿æŒä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
# =========================================================
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.ToTensor(),
])

def preprocess_image(image_path):
    """åŠ è½½å¹¶é¢„å¤„ç†è¾“å…¥å›¾ç‰‡"""
    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")

    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = cv2.resize(image, (64, 64))
    image_tensor = transform(image)
    image_tensor = image_tensor.unsqueeze(0).to(device)  # å¢åŠ  batch ç»´åº¦
    return image_tensor, image

# =========================================================
# äº”ã€é¢„æµ‹å‡½æ•°
# =========================================================
def predict_image(model, image_tensor):
    """è¾“å…¥å›¾åƒ tensorï¼Œè¾“å‡ºé¢„æµ‹ç»“æœï¼ˆçŒ«/éçŒ«ï¼‰"""
    with torch.no_grad():
        output = model(image_tensor)
        prob = output.item()
        pred = 1 if prob > 0.5 else 0
    return pred, prob

# =========================================================
# å…­ã€äº¤äº’å¼é¢„æµ‹
# =========================================================
if __name__ == "__main__":
    while True:
        image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„ï¼ˆæ”¯æŒ jpg/png/bmpï¼‰ï¼š")
        try:
            image_tensor, image_show = preprocess_image(image_path)
            pred, prob = predict_image(model, image_tensor)

            # æ˜¾ç¤ºç»“æœ
            plt.imshow(image_show)
            plt.axis("off")
            title = f"é¢„æµ‹ç»“æœ: çŒ« ğŸ˜º (ç½®ä¿¡åº¦ {prob:.3f})" if pred == 1 else f"é¢„æµ‹ç»“æœ: éçŒ« ğŸ˜¶ (ç½®ä¿¡åº¦ {1 - prob:.3f})"
            plt.title(title)

            if pred == 1:
                print(f"âœ… æ¨¡å‹é¢„æµ‹ç»“æœï¼šè¿™æ˜¯ä¸€åªçŒ«ï¼ï¼ˆç½®ä¿¡åº¦ {prob:.3f}ï¼‰")
            else:
                print(f"âŒ æ¨¡å‹é¢„æµ‹ç»“æœï¼šè¿™ä¸æ˜¯çŒ«ã€‚ï¼ˆç½®ä¿¡åº¦ {1 - prob:.3f}ï¼‰")
            plt.show()

        except Exception as e:
            print(e)

        again = input("æ˜¯å¦ç»§ç»­é¢„æµ‹å…¶ä»–å›¾ç‰‡ï¼Ÿ(y/n): ")
        if again.lower() != "y":
            print("ç¨‹åºç»“æŸã€‚")
            break
