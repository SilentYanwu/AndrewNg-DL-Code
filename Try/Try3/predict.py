# predict.py
import torch
import cv2
import numpy as np
import os, sys
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms
import argparse

# ä» model.py å¯¼å…¥å…±äº«çš„CNNæ¨¡å‹
from model import SignCNN

# è®¾ç½® Matplotlib ä¸­æ–‡æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨é»‘ä½“æ˜¾ç¤ºä¸­æ–‡
plt.rcParams['axes.unicode_minus'] = False    # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# ä½¿ç”¨æ¨¡å‹è®­ç»ƒæ—¶çš„å°ºå¯¸è¿›è¡Œæ¨ç†ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
INFER_SIZE = 64 

def fix_paths():
    """
    ä¿®å¤å¯¼å…¥è·¯å¾„å’Œæ–‡ä»¶è·¯å¾„ï¼Œç¡®ä¿æ¨¡å—æ­£ç¡®å¯¼å…¥
    
    åŠŸèƒ½:
        - å°†å½“å‰ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
        - åˆ‡æ¢åˆ°å½“å‰å·¥ä½œç›®å½•
    """
    # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # å°†å½“å‰ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„ï¼Œç¡®ä¿èƒ½æ­£ç¡®å¯¼å…¥æœ¬åœ°æ¨¡å—
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # åˆ‡æ¢åˆ°å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
    os.chdir(current_dir)

def load_model(model_path, device):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    
    å‚æ•°:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        device: è¿è¡Œè®¾å¤‡ (CPU/GPU)
        
    è¿”å›:
        model: åŠ è½½å¥½æƒé‡çš„æ¨¡å‹ï¼ˆè®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼‰
    """
    # åˆå§‹åŒ–æ¨¡å‹ç»“æ„ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    model = SignCNN(num_classes=6).to(device)
    
    # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    model.load_state_dict(torch.load(model_path, map_location=device))
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutç­‰è®­ç»ƒä¸“ç”¨å±‚ï¼‰
    model.eval()
    
    return model

def preprocess_image(image_path_or_array):
    """
    å›¾åƒé¢„å¤„ç†å‡½æ•°ï¼šå¤„ç†æ–‡ä»¶è·¯å¾„æˆ–numpyæ•°ç»„
    
    å‚æ•°:
        image_path_or_array: å›¾ç‰‡æ–‡ä»¶è·¯å¾„æˆ–numpyæ•°ç»„
        
    è¿”å›:
        image_tensor: é¢„å¤„ç†åçš„å¼ é‡ [1, C, H, W]
        image_rgb: åŸå§‹RGBå›¾åƒï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        
    å¼‚å¸¸:
        ValueError: å½“æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶æ—¶æŠ›å‡º
    """
    # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥
    if isinstance(image_path_or_array, str):
        # ä»æ–‡ä»¶è·¯å¾„è¯»å–å›¾ç‰‡
        image = cv2.imread(image_path_or_array)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path_or_array}")
    else:
        # å‡è®¾è¾“å…¥å·²ç»æ˜¯numpyæ•°ç»„ï¼ˆBGRæ ¼å¼ï¼‰
        image = image_path_or_array

    # 1. é¢œè‰²ç©ºé—´è½¬æ¢ï¼šBGR -> RGB
    if len(image.shape) == 2: 
        # ç°åº¦å›¾è½¬RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    else:
        # BGRå›¾è½¬RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
    # 2. è½¬æ¢ä¸ºPIL Imageæ ¼å¼ï¼ˆä¾¿äºä½¿ç”¨torchvisionå˜æ¢ï¼‰
    image_pil = Image.fromarray(image_rgb)
    
    # 3. åº”ç”¨ä¸éªŒè¯é›†/æµ‹è¯•é›†å®Œå…¨ç›¸åŒçš„é¢„å¤„ç†å˜æ¢
    preprocess_transform = transforms.Compose([
        transforms.Resize((INFER_SIZE, INFER_SIZE)),  # è°ƒæ•´åˆ°æ¨¡å‹è®­ç»ƒæ—¶çš„å°ºå¯¸
        transforms.ToTensor(),                        # è½¬æ¢ä¸ºTensorå¹¶å½’ä¸€åŒ–åˆ°[0,1]
        transforms.Normalize(                       # å½’ä¸€åŒ–
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
        
    ])
    
    # 4. åº”ç”¨å˜æ¢å¹¶å¢åŠ batchç»´åº¦ [C, H, W] -> [1, C, H, W]
    image_tensor = preprocess_transform(image_pil).unsqueeze(0)
    
    return image_tensor, image_rgb

def predict_and_show(model, image_path, device, classes):
    """
    æ‰§è¡Œå•å¼ å›¾ç‰‡é¢„æµ‹å¹¶å¯è§†åŒ–ç»“æœ
    
    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        device: è¿è¡Œè®¾å¤‡
        classes: ç±»åˆ«æ ‡ç­¾åˆ—è¡¨
    """
    try:
        # é¢„å¤„ç†å›¾åƒ
        tensor, original_rgb = preprocess_image(image_path)
        tensor = tensor.to(device)
    except ValueError as e:
        print(f"âŒ å›¾åƒå¤„ç†é”™è¯¯: {e}")
        return

    # æ¨¡å‹æ¨ç†ï¼ˆä¸è®¡ç®—æ¢¯åº¦ä»¥æé«˜æ•ˆç‡ï¼‰
    with torch.no_grad():
        # å‰å‘ä¼ æ’­
        outputs = model(tensor)
        
        # è®¡ç®—softmaxæ¦‚ç‡
        probs = torch.softmax(outputs, dim=1)
        
        # è·å–æœ€å¤§æ¦‚ç‡å€¼å’Œå¯¹åº”çš„ç±»åˆ«ç´¢å¼•
        conf, pred = torch.max(probs, 1)
        
        # è·å–é¢„æµ‹æ ‡ç­¾å’Œç½®ä¿¡åº¦
        label = classes[pred.item()]
        conf_value = conf.item() * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”

    # æ‰“å°é¢„æµ‹ç»“æœ
    print(f"ğŸ“ æ–‡ä»¶: {os.path.basename(image_path)}")
    print(f"  ğŸ¯ é¢„æµ‹ç±»åˆ«: {label}")
    print(f"  ğŸ“Š ç½®ä¿¡åº¦: {conf_value:.2f}%")

    # ä½¿ç”¨Matplotlibæ˜¾ç¤ºç»“æœï¼ˆæ¯”OpenCVçª—å£æ›´å‹å¥½ï¼‰
    plt.figure(figsize=(8, 6))
    plt.imshow(original_rgb)  # æ˜¾ç¤ºåŸå§‹RGBå›¾åƒ
    
    # è®¾ç½®æ ‡é¢˜
    title_text = f"é¢„æµ‹ç»“æœ: {label} (ç½®ä¿¡åº¦: {conf_value:.2f}%)"
    plt.title(title_text, fontsize=14, fontweight='bold')
    plt.axis("off")  # éšè—åæ ‡è½´
    
    # æ˜¾ç¤ºå›¾åƒ
    plt.tight_layout()
    plt.show()

def batch_predict(model, input_dir, device, classes):
    """
    æ‰¹é‡é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
    
    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        input_dir: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
        device: è¿è¡Œè®¾å¤‡
        classes: ç±»åˆ«æ ‡ç­¾åˆ—è¡¨
    """
    print(f"ğŸ” æ‰«ææ–‡ä»¶å¤¹: {input_dir}")
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    valid_extensions = ('.jpg', '.png', '.jpeg', '.bmp', '.tiff')
    
    for filename in os.listdir(input_dir):
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if filename.lower().endswith(valid_extensions):
            img_path = os.path.join(input_dir, filename)
            
            try:
                # é¢„å¤„ç†å’Œé¢„æµ‹
                tensor, _ = preprocess_image(img_path)
                tensor = tensor.to(device)
                
                with torch.no_grad():
                    outputs = model(tensor)
                    probs = torch.softmax(outputs, dim=1)
                    conf, pred = torch.max(probs, 1)
                    
                    # æ‰“å°ç»“æœï¼ˆåŒ…å«ç½®ä¿¡åº¦ï¼‰
                    label = classes[pred.item()]
                    conf_value = conf.item() * 100
                    print(f"ğŸ“„ {filename} -> ğŸ¯ {label} ({conf_value:.2f}%)")
                    
            except Exception as e:
                print(f"âŒ è·³è¿‡ {filename}: {e}")

def main(args):
    """
    ä¸»é¢„æµ‹å‡½æ•°
    
    åŠŸèƒ½:
        - åŠ è½½æ¨¡å‹
        - æ ¹æ®è¾“å…¥ç±»å‹ï¼ˆæ–‡ä»¶/æ–‡ä»¶å¤¹ï¼‰æ‰§è¡Œé¢„æµ‹
        - å¤„ç†é¢„æµ‹ç»“æœ
    """
    # è®¾ç½®è¿è¡Œè®¾å¤‡ï¼ˆä¼˜å…ˆGPUï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # å®šä¹‰ç±»åˆ«æ ‡ç­¾ï¼ˆåº”ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
    classes = [0, 1, 2, 3, 4, 5]  # å¯ä»¥æ ¹æ®å®é™…ç±»åˆ«åç§°ä¿®æ”¹
    
    # åŠ è½½æ¨¡å‹
    print(f"ğŸ“¦ æ­£åœ¨ä» {args.model} åŠ è½½æ¨¡å‹...")
    try:
        model = load_model(args.model, device)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ ¹æ®è¾“å…¥ç±»å‹æ‰§è¡Œä¸åŒçš„é¢„æµ‹æ¨¡å¼
    if os.path.isfile(args.input):
        print("--- å•å¼ å›¾ç‰‡é¢„æµ‹æ¨¡å¼ ---")
        predict_and_show(model, args.input, device, classes)
        
    elif os.path.isdir(args.input):
        print("--- æ‰¹é‡æ–‡ä»¶å¤¹é¢„æµ‹æ¨¡å¼ ---")
        batch_predict(model, args.input, device, classes)
    else:
        print(f"âŒ é”™è¯¯: è¾“å…¥è·¯å¾„æ— æ•ˆ: {args.input}")

if __name__ == "__main__":
    # ä¿®å¤è·¯å¾„ï¼ˆåœ¨å¯¼å…¥æœ¬åœ°æ¨¡å—ä¹‹å‰ï¼‰
    fix_paths()
        
    # äº¤äº’å¼å¾ªç¯é¢„æµ‹
    continue_predicting = True
    while continue_predicting:
    
        # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°
        parser = argparse.ArgumentParser(description="æ‰‹è¯­CNNæ¨¡å‹é¢„æµ‹å·¥å…·")
        parser.add_argument('-m', '--model', type=str, default='runs/best_model.pt',
                        help='è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„ (.pt æ–‡ä»¶)')
        
        # äº¤äº’å¼è¾“å…¥å›¾ç‰‡è·¯å¾„
        test_image = input("ğŸ“ è¯·è¾“å…¥è¦é¢„æµ‹çš„å›¾ç‰‡è·¯å¾„ï¼š")
        parser.add_argument('-i', '--input', type=str, default=test_image,
                        help='è¦é¢„æµ‹çš„å›¾ç‰‡è·¯å¾„æˆ–å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„')
        
        # è§£æå‚æ•°
        args = parser.parse_args()

        # æ‰§è¡Œé¢„æµ‹
        main(args)
        
        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        answer = input("\nğŸ”„ æ˜¯å¦ç»§ç»­é¢„æµ‹ï¼Ÿ(y/n): ").lower()
        if answer != 'y':
            continue_predicting = False
            print("ğŸ‘‹ ç¨‹åºé€€å‡ºï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")