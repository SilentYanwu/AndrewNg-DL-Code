 FaceNet 人脸识别项目简介

这是一个基于 PyTorch 复现的 FaceNet 人脸识别系统。该项目能够将人脸图像转换成一个 128维的向量（Embedding），通过计算向量之间的欧氏距离来判断两张脸是否属于同一个人。

1. 项目结构说明

整个项目由三个核心脚本组成，分工明确：

🛠️ models/facenet.py (模型大脑)

这是神经网络的定义文件。

它定义了 FaceNet 类和核心的 InceptionBlock 模块。

作用：它不关心图片是谁，只负责接收一张张量（Tensor），经过层层卷积计算，最后“吐出”一个代表这张人脸特征的 128维向量。

关键技术：实现了 Inception 架构的并行分支结构，并处理了不同卷积层的拼接逻辑。

🖼️ utils/img_utils.py (数据助手)

这是图像预处理工具箱。

它负责脏活累活：读取图片文件、调整大小（Resize 到 96x96）、通道转换（BGR转RGB）、归一化以及转成 PyTorch 需要的 Tensor 格式。

作用：它是连接“原始图片文件”和“神经网络模型”的桥梁。

🚀 main.py (总指挥)

这是主运行脚本。

它负责加载模型权重，建立人脸数据库（读取 data/images 下的图片并存好特征）。

它实现了两个核心业务逻辑：

verify() (1对1验证)：判断“这张照片是不是某人？”（用于门禁等）。

who_is_it() (1对N识别)：判断“这张照片是谁？”（用于打卡、检索）。

2. Inception V1 (GoogLeNet) 原理简述

本项目使用的骨干网络基于 Inception V1 架构。在深度学习早期，为了提升性能，大家都在拼命把网络做“深”（层数更多）。但 Inception 另辟蹊径，它把网络做**“宽”**了。

它的核心原理可以概括为两点：

A. “我全都要”的并行结构

在处理一张人脸时，我们有时候需要看全局轮廓（比如脸型），有时候需要看局部细节（比如眼角的皱纹）。

传统网络：每一层只能选择一种卷积核（比如只能选 3x3）。

Inception：在一个层（Block）里，同时使用 1x1、3x3、5x5 的卷积核以及池化层。

5x5 负责看大视野（全局）。

3x3 负责看中等视野。

1x1 负责看微小细节。

最后将这些不同尺度提取到的特征**拼接（Concat）**在一起。这样模型就能自动学习到最适合的特征组合。

B. 1x1 卷积的“降维打击” (Bottleneck)

如果直接并行计算 3x3 和 5x5 卷积，计算量会爆炸，速度极慢。
Inception 引入了 1x1 卷积 作为“瓶颈层”：

在进行昂贵的 3x3 或 5x5 卷积之前，先用 1x1 卷积把通道数（厚度）压缩。

这就像是把高清图片先压缩一下再处理，既保留了关键信息，又极大地减少了参数量和计算时间，让网络可以做得更深而不卡顿。