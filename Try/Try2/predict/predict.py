'''
PyTorch GPU ç‰ˆæœ¬ - äº¤äº’å¼æ¨¡å‹é¢„æµ‹è„šæœ¬
æ”¯æŒé€‰æ‹©ä¸åŒæ ¼å¼çš„æ¨¡å‹æ–‡ä»¶
'''
import torch
import torch.nn as nn
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os,sys

# æ·»åŠ è·¯å¾„ä¿®å¤ä»£ç 
def fix_paths():
    """ä¿®å¤å¯¼å…¥è·¯å¾„å’Œæ–‡ä»¶è·¯å¾„"""
    # å°†å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # åˆ‡æ¢åˆ°å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
    os.chdir(current_dir)

# åœ¨å¯¼å…¥æœ¬åœ°ä¹‹å‰è°ƒç”¨
fix_paths()

# è®¾ç½® Matplotlib ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„å­—ä½“ï¼ˆWindows æ¨è SimHeiï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei']   # æˆ–è€… ['Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False     # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# =========================================================
# ä¸€ã€å›¾ç‰‡é¢„å¤„ç†å‡½æ•°
# =========================================================
def preprocess_image(image_path, target_size=(64, 64)):
    """
    é€šç”¨å›¾ç‰‡é¢„å¤„ç†å‡½æ•°ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    """
    # ä½¿ç”¨OpenCVè¯»å–å›¾ç‰‡
    image = cv2.imread(image_path)
    
    if image is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
    
    # è½¬æ¢é¢œè‰²ç©ºé—´ BGR -> RGB (OpenCVé»˜è®¤æ˜¯BGRï¼Œä½†æˆ‘ä»¬éœ€è¦RGB)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # ä½¿ç”¨OpenCVè°ƒæ•´å°ºå¯¸åˆ°64x64
    image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)
    
    # å¤„ç†ä¸åŒé€šé“æ•°
    if len(image.shape) == 2:  # ç°åº¦å›¾
        image = np.stack([image, image, image], axis=-1)
    
    # å½’ä¸€åŒ–
    if image.max() > 1.0:
        image = image / 255.0
    
    # å±•å¹³å¹¶è½¬ç½® (ä¿æŒä¸è®­ç»ƒæ—¶ç›¸åŒçš„æ ¼å¼)
    image_flat = image.reshape((1, -1)).T
    
    return image_flat, image

# =========================================================
# äºŒã€å®šä¹‰ç›¸åŒçš„ç¥ç»ç½‘ç»œæ¨¡å‹
# =========================================================
class ThreeLayerNN(nn.Module):
    def __init__(self, input_size=12288, hidden1_size=25, hidden2_size=12, output_size=6):
        super(ThreeLayerNN, self).__init__()
        self.layer1 = nn.Linear(input_size, hidden1_size)
        self.layer2 = nn.Linear(hidden1_size, hidden2_size)
        self.layer3 = nn.Linear(hidden2_size, output_size)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.relu(self.layer2(x))
        x = self.layer3(x)
        return x

# =========================================================
# ä¸‰ã€æ¨¡å‹åŠ è½½å‡½æ•°
# =========================================================
def load_model_by_type(model_type="auto"):
    """
    æ ¹æ®ç±»å‹åŠ è½½æ¨¡å‹
    model_type: "dict" - å­—å…¸ç‰ˆ, "full" - å®Œæ•´ç‰ˆ, "auto" - è‡ªåŠ¨é€‰æ‹©
    """
    model_files = {
        "dict": "three_layer_nn_model.pth",
        "full": "three_layer_nn_full_model.pth"
    }
    
    if model_type == "auto":
        # è‡ªåŠ¨é€‰æ‹©ï¼šä¼˜å…ˆä½¿ç”¨å®Œæ•´ç‰ˆï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å­—å…¸ç‰ˆ
        if os.path.exists(model_files["full"]):
            model_path = model_files["full"]
            print("âœ… è‡ªåŠ¨é€‰æ‹©: å®Œæ•´ç‰ˆæ¨¡å‹")
        elif os.path.exists(model_files["dict"]):
            model_path = model_files["dict"]
            print("âœ… è‡ªåŠ¨é€‰æ‹©: å­—å…¸ç‰ˆæ¨¡å‹")
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
            return None
    else:
        model_path = model_files.get(model_type)
        if not model_path or not os.path.exists(model_path):
            print(f"âŒ æ‰¾ä¸åˆ°æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶: {model_files.get(model_type)}")
            return None
    
    print(f"ğŸ“ åŠ è½½æ¨¡å‹: {model_path}")
    return load_model(model_path)

def load_model(model_path):
    """
    åŠ è½½æŒ‡å®šè·¯å¾„çš„æ¨¡å‹
    """
    try:
        # åŠ è½½æ¨¡å‹æ–‡ä»¶
        checkpoint = torch.load(model_path, map_location=device)
        
        # åˆ¤æ–­æ¨¡å‹æ ¼å¼å¹¶åŠ è½½
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            print("âœ… æ£€æµ‹åˆ°å®Œæ•´ç‰ˆæ¨¡å‹æ ¼å¼")
            
            # ä»checkpointä¸­è·å–æ¨¡å‹é…ç½®
            if 'model_config' in checkpoint:
                config = checkpoint['model_config']
                model = ThreeLayerNN(
                    input_size=config.get('input_size', 12288),
                    hidden1_size=config.get('hidden1_size', 25),
                    hidden2_size=config.get('hidden2_size', 12),
                    output_size=config.get('output_size', 6)
                ).to(device)
            else:
                model = ThreeLayerNN().to(device)
            
            model.load_state_dict(checkpoint['model_state_dict'])
            
            # æ˜¾ç¤ºå‡†ç¡®ç‡ä¿¡æ¯
            if 'test_accuracy' in checkpoint:
                print(f"ğŸ“Š æ¨¡å‹æµ‹è¯•å‡†ç¡®ç‡: {checkpoint['test_accuracy']:.2f}%")
                
        else:
            print("âœ… æ£€æµ‹åˆ°å­—å…¸ç‰ˆæ¨¡å‹æ ¼å¼")
            model = ThreeLayerNN().to(device)
            model.load_state_dict(checkpoint)
        
        model.eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

# =========================================================
# å››ã€é¢„æµ‹å‡½æ•°
# =========================================================
def predict_image(model, image_path):
    """é¢„æµ‹å•å¼ å›¾ç‰‡"""
    # é¢„å¤„ç†å›¾ç‰‡
    image_flat, original_image = preprocess_image(image_path)
    
    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    image_tensor = torch.FloatTensor(image_flat.T).to(device)
    
    # é¢„æµ‹
    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = torch.softmax(outputs, dim=1)
        confidence, predicted = torch.max(probabilities, 1)
        prediction = predicted.cpu().numpy()[0]
        confidence_score = confidence.cpu().numpy()[0]
    
    return prediction, confidence_score, original_image

# =========================================================
# äº”ã€æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
# =========================================================
def check_model_files():
    """æ£€æŸ¥å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶"""
    model_files = {
        "dict": "three_layer_nn_model.pth",
        "full": "three_layer_nn_full_model.pth"
    }
    
    available_models = []
    for model_type, filename in model_files.items():
        if os.path.exists(filename):
            available_models.append(model_type)
            print(f"âœ… {model_type}ç‰ˆ: {filename} (å­˜åœ¨)")
        else:
            print(f"âŒ {model_type}ç‰ˆ: {filename} (ä¸å­˜åœ¨)")
    
    return available_models

# =========================================================
# å…­ã€å•å¼ å›¾ç‰‡é¢„æµ‹
# =========================================================
def single_image_prediction(model):
    """å•å¼ å›¾ç‰‡é¢„æµ‹"""
    print("\nğŸ“¸ å•å¼ å›¾ç‰‡é¢„æµ‹")
    print("-" * 30)
    
    # è·å–å›¾ç‰‡è·¯å¾„
    default_path = "images/5.png"
    if os.path.exists(default_path):
        image_path = input(f"è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„ [é»˜è®¤: {default_path}]: ").strip()
        if not image_path:
            image_path = default_path
    else:
        image_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
    
    # ç§»é™¤å¯èƒ½çš„å¼•å·
    image_path = image_path.strip('"').strip("'")
    
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨: {image_path}")
        return
    
    try:
        prediction, confidence, original_image = predict_image(model, image_path)
        
        # æ˜¾ç¤ºç»“æœ
        plt.figure(figsize=(10, 6))
        plt.imshow(original_image)
        plt.title(f"é¢„æµ‹ç»“æœ: {prediction} (ç½®ä¿¡åº¦: {confidence:.2%})", fontsize=16, pad=20)
        plt.axis('off')
        plt.tight_layout()
        plt.show()
        
        print(f"ğŸ¯ é¢„æµ‹ç»“æœ: {prediction}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence:.2%}")
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")

# =========================================================
# ä¸ƒã€æ‰¹é‡å›¾ç‰‡é¢„æµ‹
# =========================================================
def batch_image_prediction(model):
    """æ‰¹é‡å›¾ç‰‡é¢„æµ‹"""
    print("\nğŸ“ æ‰¹é‡å›¾ç‰‡é¢„æµ‹")
    print("-" * 30)
    
    folder_path = input("è¯·è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„: ").strip().strip('"').strip("'")
    
    if not os.path.exists(folder_path):
        print(f"âŒ æ–‡ä»¶å¤¹è·¯å¾„ä¸å­˜åœ¨: {folder_path}")
        return
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
    image_files = []
    
    for file in os.listdir(folder_path):
        if any(file.lower().endswith(ext) for ext in image_extensions):
            image_files.append(os.path.join(folder_path, file))
    
    if not image_files:
        print(f"âŒ åœ¨æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"ğŸ” æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    
    results = []
    correct_predictions = 0
    total_predictions = 0
    
    for i, image_file in enumerate(image_files, 1):
        try:
            prediction, confidence, _ = predict_image(model, image_file)
            results.append((image_file, prediction, confidence))
            
            filename = os.path.basename(image_file)
            print(f"{i:2d}/{len(image_files)}: {filename:20s} â†’ é¢„æµ‹: {prediction}, ç½®ä¿¡åº¦: {confidence:.2%}")
            
            # å¦‚æœæ–‡ä»¶ååŒ…å«çœŸå®æ ‡ç­¾ï¼ˆä¾‹å¦‚: "5_cat.png"ï¼‰ï¼Œå¯ä»¥è¿›è¡Œæ¯”è¾ƒ
            # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ®æ‚¨çš„æ–‡ä»¶åæ ¼å¼è°ƒæ•´
            if '_' in filename:
                true_label = filename.split('_')[0]
                if true_label.isdigit() and int(true_label) == prediction:
                    correct_predictions += 1
                total_predictions += 1
                
        except Exception as e:
            print(f"âŒ å¤„ç† {os.path.basename(image_file)} æ—¶å‡ºé”™: {e}")
            results.append((image_file, None, 0.0))
    
    # å¦‚æœæœ‰çœŸå®æ ‡ç­¾æ¯”è¾ƒï¼Œæ˜¾ç¤ºå‡†ç¡®ç‡
    if total_predictions > 0:
        accuracy = correct_predictions / total_predictions
        print(f"\nğŸ“ˆ æ‰¹é‡é¢„æµ‹å‡†ç¡®ç‡: {accuracy:.2%} ({correct_predictions}/{total_predictions})")
    
    return results

# =========================================================
# å…«ã€æ¨¡å‹ä¿¡æ¯æ˜¾ç¤º
# =========================================================
def show_model_info(model):
    """æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯"""
    print("\nğŸ“‹ æ¨¡å‹ä¿¡æ¯")
    print("-" * 30)
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"ğŸ—ï¸  æ¨¡å‹æ¶æ„: ThreeLayerNN")
    print(f"ğŸ”¢ æ€»å‚æ•°é‡: {total_params:,}")
    print(f"ğŸ¯ å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"âš™ï¸  è®¾å¤‡: {device}")
    
    # æ˜¾ç¤ºå„å±‚ä¿¡æ¯
    print("\nğŸ“Š å„å±‚ä¿¡æ¯:")
    for name, layer in model.named_children():
        if hasattr(layer, 'weight'):
            print(f"  {name}: {tuple(layer.weight.shape)}")

# =========================================================
# ä¹ã€ä¸»äº¤äº’ç•Œé¢
# =========================================================
def main_interactive():
    """ä¸»äº¤äº’ç•Œé¢"""
    current_model = None
    
    while True:
        print("\n" + "="*60)
        print("ğŸ¯ PyTorch ä¸‰å±‚ç¥ç»ç½‘ç»œ - äº¤äº’å¼é¢„æµ‹ç³»ç»Ÿ")
        print("="*60)
        
        # æ˜¾ç¤ºå½“å‰åŠ è½½çš„æ¨¡å‹
        if current_model:
            print(f"âœ… å½“å‰å·²åŠ è½½æ¨¡å‹")
        else:
            print("âŒ å½“å‰æœªåŠ è½½æ¨¡å‹")
        
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ“ é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹")
        print("2. ğŸ“¸ å•å¼ å›¾ç‰‡é¢„æµ‹")
        print("3. ğŸ“ æ‰¹é‡å›¾ç‰‡é¢„æµ‹")
        print("4. ğŸ“‹ æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯")
        print("5. ğŸ” æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")
        print("6. ğŸšª é€€å‡ºç³»ç»Ÿ")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-6): ").strip()
        
        if choice == '1':
            # é€‰æ‹©å¹¶åŠ è½½æ¨¡å‹
            print("\nğŸ“ é€‰æ‹©æ¨¡å‹ç±»å‹:")
            print("1. è‡ªåŠ¨é€‰æ‹© (æ¨è)")
            print("2. å­—å…¸ç‰ˆæ¨¡å‹ (three_layer_nn_model.pth)")
            print("3. å®Œæ•´ç‰ˆæ¨¡å‹ (three_layer_nn_full_model.pth)")
            
            model_choice = input("è¯·é€‰æ‹©æ¨¡å‹ç±»å‹ (1-3): ").strip()
            
            if model_choice == '1':
                current_model = load_model_by_type("auto")
            elif model_choice == '2':
                current_model = load_model_by_type("dict")
            elif model_choice == '3':
                current_model = load_model_by_type("full")
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
            
        elif choice == '2':
            # å•å¼ å›¾ç‰‡é¢„æµ‹
            if current_model:
                single_image_prediction(current_model)
            else:
                print("âŒ è¯·å…ˆåŠ è½½æ¨¡å‹")
                
        elif choice == '3':
            # æ‰¹é‡å›¾ç‰‡é¢„æµ‹
            if current_model:
                batch_image_prediction(current_model)
            else:
                print("âŒ è¯·å…ˆåŠ è½½æ¨¡å‹")
                
        elif choice == '4':
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            if current_model:
                show_model_info(current_model)
            else:
                print("âŒ è¯·å…ˆåŠ è½½æ¨¡å‹")
                
        elif choice == '5':
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            available_models = check_model_files()
            if not available_models:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
            else:
                print(f"âœ… å¯ç”¨çš„æ¨¡å‹: {', '.join(available_models)}")
                
        elif choice == '6':
            # é€€å‡ºç³»ç»Ÿ
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            break
            
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

# =========================================================
# åã€ä¸»ç¨‹åºå…¥å£
# =========================================================
if __name__ == "__main__":
    print("ğŸš€ PyTorch ä¸‰å±‚ç¥ç»ç½‘ç»œé¢„æµ‹ç³»ç»Ÿ")
    print("ğŸ’¡ æ”¯æŒå­—å…¸ç‰ˆå’Œå®Œæ•´ç‰ˆæ¨¡å‹")
    
    # è‡ªåŠ¨æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    available_models = check_model_files()
    
    if available_models:
        print(f"\nâœ… å‘ç° {len(available_models)} ä¸ªå¯ç”¨æ¨¡å‹")
        # å¯åŠ¨äº¤äº’ç•Œé¢
        main_interactive()
    else:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬")
        print("ğŸ’¡ è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
        print("   - three_layer_nn_model.pth (å­—å…¸ç‰ˆ)")
        print("   - three_layer_nn_full_model.pth (å®Œæ•´ç‰ˆ)")